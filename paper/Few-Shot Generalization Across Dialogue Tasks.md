####Few-Shot Generalization Across Dialogue Tasks

#####概述

基于机器学习的对话管理能够学习复杂的行为来完成任务，但将其能力扩展到新领域并不简单，
我们引入循环嵌入对话策略(REDP)，该策略将system action和dialogue states嵌入到同一个向量空间中.
在此任务中PERD包含一个改进的神经记忆组件和注意力机制，显著优于基线LSTM分类器

#####当前问题

- AIML系统

    完全手工制作的系统，开发人员必须手工编写每一个可能的对话
- 端到端系统
    
    一旦经过训练，不适用新领域，泛化到新领域需要重新训练
- 对话中交叉任务泛化

    任务型对话一般以确定用户意图和填满槽位来做出正确的回复，当槽位缺失时，系统通常会反问
用户槽位信息，如果用户不配合偏离对话，系统应该识别出当前话题意图并做出回答，并将对话引导回
之前的话题，如下图
![偏离合作对话](picture/1652840087(1).png)

####循环嵌入式策略

基于LSTM的learn to Rank方法，大体上是将当前轮用户意图、上一轮系统行为、当前槽值状态向量化，
然后与所有的系统行为做相似度学习，以此决策当前轮次的一个或多个系统行为

![循环嵌入式策略](picture/1652844169(1).png)
- featurization

  user_input：意图和识别实体

  user_intent and system_actions: bag-of-words representations

  slots: binary vectors （需要了解如何覆盖槽位）

  如何将以上三种特征进行结合
- learn to Rank

  很多对话系统在系统决策都采用的分类方法，每次在多个系统行为中选择唯一一个
  
  Rasa选择了排序方法，判断当前对话状态和系统行为的相似度
  - 更容易实现多行为输出
  - **方便扩展行为，如新增一个行为，分类模型需要重新训练，而Ranking只需要训新增的系统行为
  和不相关的部分数据集，可能增加总体的训练速度**（需要进一步理解）

  


